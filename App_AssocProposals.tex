We begin with some useful identities. A Gaussian transition density model for a single target is given by

\begin{equation}
P(x_{t+1}|x_t) = \mathcal{N}(x_{t+1}|A x_t, Q).
\end{equation}

If the multiple step transition density is written as

\begin{equation}
P(x_{t+d}|x_t) = \mathcal{N}(x_{t+d}|A_d x_t, Q_d)
\end{equation}

then using standard identities we can write the recursion

\begin{IEEEeqnarray}{rCl}
P(x_{t+d+1}|x_{t}) & = & \int P(x_{t+d+1}|x_{t+d})P(x_{t+d}|x_t) dx_{t+d} \nonumber \\
 & = & \int \mathcal{N}(x_{t+d+1}|A x_{t+d}, Q) \mathcal{N}(x_{t+d}|A_d x_{t+d}, Q_d) dx_{t+d} \nonumber \\
 & = & \mathcal{N}(x_{t+d+1}|A \times A_d x_t, A Q_d A^T + Q).
\end{IEEEeqnarray}

Hence, by induction, we have

\begin{IEEEeqnarray}{rCl}
A_d & = & A^d \nonumber \\
Q_d & = & \sum_{k=0}^{d-1} (A^k) Q (A^k)^T.
\end{IEEEeqnarray}

Also, for $\lambda_t \ne 0$, and using the factorisation of equation~\ref{eq:MTFactorisedLikelihood}

\begin{IEEEeqnarray}{rCl}
P(y_{t+d}^{(\lambda_{t+d})}|x_{t}) & \propto & \int \mathcal{N}(y_{t+d}^{(\lambda_{t+d})}|C_{t+d} x_{t+d}, R) \mathcal{N}(x_{t+d}|A_d x_t, Q_d) dx_{t+d} \nonumber \\
                                   & = & \mathcal{N}(y_{t+d}^{(\lambda_{t+d})}|C_{t+d} A_d x_t, R_d)
\end{IEEEeqnarray}

where 

\begin{IEEEeqnarray}{rCl}
R_d & = & R + C_{t+d} Q_d C_{t+d}^T.
\end{IEEEeqnarray}

Here we derive an approximation for the `optimal' association proposal for a linear-Gaussian model. For nonlinear models, linear approximations may be used in the style of the EKF. The optimum form for the proposal distribution is given by

\begin{IEEEeqnarray}{rCl}
q(\lambda_{t-L+1:t}|x_{t-L}, Y_{t-L+1:t}) & & \nonumber \\
 & = & P(\lambda_{t-L+1:t}|x_{t-L}, Y_{t-L+1:t}) \nonumber \\
 & \propto & P(Y_{t-L+1:t}|\lambda_{t-L+1:t},x_{t-L}) P(\lambda_{t-L+1:t}|x_{t-L}) \nonumber \\
 & = & \prod_{\substack{k=1:L\\l=t-L+k}} P(Y_{l}|Y_{l+1:t} \lambda_{l:t}, x_{t-L}) P(\lambda_{l}).
\label{eq:AssPropSequential}
\end{IEEEeqnarray}

where the backward-predictive likelihood factors may be expanded as

\begin{equation}
P(Y_{l}|Y_{l+1:t} \lambda_{l:t}, x_{t-L}) = \int P(Y_{l}|x_{l}, \lambda_{l}) P(x_{l}|Y_{l+1:t}, \lambda_{l+1:t}, x_{t-L}) dx_{l}.
\label{eq:AssPropBackPredLike}
\end{equation}

We use the approximation

\begin{equation}
P(x_{l}|Y_{l+1:t}, \lambda_{l+1:t}, x_{t-L}) \approx P(x_{l}|Y_{l+d}, \lambda_{l+d}, x_{t-L})
\end{equation}

where $d$ is the minimum positive value such that $\lambda_{l+d} \ne 0$. This can be expanded as

\begin{IEEEeqnarray}{rCl}
\IEEEeqnarraymulticol{3}{l}{P(x_{l}|Y_{l+d}, \lambda_{l+d}, x_{t-L})} \nonumber \\
\qquad \qquad & \propto & \int P(Y_{l+d}|x_{l+d}, \lambda_{l+d}) P(x_{l+d}|x_{l}) dx_{l+d} P(x_{l}|x_{t-L}) \nonumber \\
 & \propto & \int \mathcal{N}(y_{l+d}^{(\lambda_{l+d})}|C x_{l+d}, R) \mathcal{N}(x_{l+d}|A_d x_{l}, Q_d) dx_{l+d} \mathcal{N}(x_{l}|A_k x_{t-L}, Q_k) \nonumber \\
 & \propto & \mathcal{N}(y_{l+d}^{(\lambda_{l+d})}|C_{l+d} A_d x_{l}, R + C_{l+d} Q_d C_{l+d}^T) \mathcal{N}(x_{l}|A_k x_{t-L}, Q_k) \nonumber .
\label{eq:AssPropStateExpansion}
\end{IEEEeqnarray}

Substituting equation~\ref{eq:AssPropStateExpansion} into equation~\ref{eq:AssPropBackPredLike}, we have

\begin{IEEEeqnarray}{rCl}
\IEEEeqnarraymulticol{3}{l}{P(Y_{l}|Y_{l+1:t} \lambda_{l:t}, x_{t-L})} \nonumber \\
\qquad & \stackrel{\sim}{\propto} & \int \mathcal{N}(y_{l}^{(\lambda_{l})}|C_{l} x_{l}, R) \mathcal{N}(y_{l+d}^{(\lambda_{l+d})}|C_{l+d} A_d x_{l}, R + C_{l+d} Q_d C_{l+d}^T) \mathcal{N}(x_{l}|A_k x_{t-L}, Q_k) dx_{l} \nonumber \\
 & \propto & \int \exp(-\frac{1}{2} \xi) dx_{l} \nonumber \\
 & \propto & \exp(-\frac{1}{2} \zeta).
\end{IEEEeqnarray}

The challenge now is to rearrange $\xi$ and hence find $\zeta$. Superscript $\lambda$s are omitted for clarity.

\begin{IEEEeqnarray}{rCl}
\xi & = & (y_{l} - C_{l} x_{l})^T R^{-1} (y_{l} - C_{l} x_{l}) \nonumber \\
    &   & + \: (y_{l+d} - C_{l+d} x_{l+d})^T R_d^{-1} (y_{l+d} - C_{l+d} x_{l+d}) \nonumber \\
    &   & + \: (x_{l} - A_k x_{t-L})^T Q_k^{-1} (x_{l} - A_k x_{t-L}) \nonumber \\
    & = & x_{l}^T \underbrace{[ C_{l}^T R^{-1} C_{l} + A_d^T C_{l+d}^T R_d^{-1} C_{l+d} A_d + Q_k^{-1} ]}_{\Sigma_{l}^{-1}} x_{l} \nonumber \\
    &   & - \: 2 \underbrace{[ y_{l}^T R^{-1} C_{l} + y_{l+d}^T R_d^{-1} C_{l+d} A_d + x_{t-L}^T A_k^T Q_k^{-1} ]}_{\mu_{l}^T \Sigma_{l}^{-1}} x_{l} \nonumber \\
    &   & + \: \underbrace{[ y_{l}^T R^{-1} y_{l} + y_{l+d}^T R_d^{-1} y_{l+d} + x_{t-L}^T A_k^T Q_k^{-1} A_k ]}_{C}
\end{IEEEeqnarray}

Carrying out the integral, an expression for $\zeta$ is now obtainable. Terms independent of $y_{l}$ are absorbed into the constant of proportionality, which is unimportant as it will cancel out during normalisation.

\begin{IEEEeqnarray}{rCl}
\zeta & = & C - \mu_{l}^T \Sigma_{l} \mu_{l} \nonumber \\
      & = & y_{l}^T \underbrace{[ I - R^{-1} C_{l} \Sigma C_{l} R^{-1} ]}_{S_{l}^{-1}} y_{l} \nonumber \\
      &   & - \: 2 \underbrace{[ y_{l+d}^T R_d^{-1} C_{l+d} A_d \Sigma_{l} C_{l}^T R^{-1} + x_{t-L}^T A_k^T Q_k^{-1} \Sigma_{l} C_{l}^T R^{-1} ]}_{m^T S^{-1}} y_{l} \nonumber \\
      &   & + \: \text{terms independent of $\zeta$}
\end{IEEEeqnarray}

Hence we arrive at the final expression

\begin{equation}
P(Y_{l}|Y_{l+1:t} \lambda_{l:t}, x_{t-L}) \propto \mathcal{N}(y_{l}^{(\lambda_{l})}|m_t, S_t).
\end{equation}

where

\begin{IEEEeqnarray}{rCl}
m_t      & = & S_t R^{-1} C_{l} \Sigma_{l} [ A_d^T C_{l}^T R_d^{-1} y_{l}^{(\lambda_{l})} + Q_k^{-1} A_k x_{t-L} ] \nonumber \\
S_t      & = & [ I - R^{-1} C_{l} \Sigma_{l} C_{l} R^{-1} ] \nonumber \\
\Sigma_t & = & [ C_{l}^T R^{-1} C_{l} + A_d^T C_{l+d}^T R_d^{-1} C_{l+d} A_d + Q_k^{-1} ]^{-1}
\end{IEEEeqnarray}

and as before

\begin{IEEEeqnarray}{rCl}
A_d & = & A^d \nonumber \\
Q_d & = & \sum_{k=0}^{d-1} (A^k) Q (A^k)^T \nonumber \\
R_d & = & R + C_{l+d} Q_d C_{l+d}^T .
\end{IEEEeqnarray}

We need a different expression for the case when $\lambda_{l+d} = 0$ for all $d = 1:t-l$. In this case, the future observations tell us nothing about the current state. Now the expression for the backward state prediction becomes

\begin{equation}
P(x_{l}|Y_{l+1:t}, \lambda_{l+1:t}, x_{t-L}) = P(x_{l}| x_{t-L})
\end{equation}

Proceeding as before, we have

\begin{IEEEeqnarray}{rCl}
P(Y_{l}|Y_{l+1:t} \lambda_{l:t}, x_{t-L}) &  & \nonumber \\
 & \propto & \int \mathcal{N}(y_{l}^{(\lambda_{l})}|C_{l} x_{l}, R) \mathcal{N}(x_{l}|A_k x_{t-L}, Q_k) dx_{l} \nonumber \\
 & = & \mathcal{N}(y_{l}^{(\lambda_{l})}|C_{l} A_k x_{t-L}, R_k).
\end{IEEEeqnarray}

Finally, in the special case where $\lambda_{l} = 0$,

\begin{equation}
P(Y_{l}|Y_{l+1:t} \lambda_{l:t}, x_{t-L}) \propto V^{-1}.
\end{equation}